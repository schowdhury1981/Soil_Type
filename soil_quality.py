# -*- coding: utf-8 -*-
"""Soil_Quality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fSHt8foCI9zk6Kt-BJjcQXz8oerlLizZ
"""

import pandas as pd

# Load the uploaded dataset to inspect its contents
file_path = '/bangladesh_divisions_dataset.csv'
dataset = pd.read_csv(file_path)

# Display the first few rows to understand its structure
dataset.head()

from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# Preprocessing: Encoding categorical variables
label_encoders = {}
for col in ['Soil_Type', 'Land_Use_Type', 'Crop_Suitability', 'Season']:
    le = LabelEncoder()
    dataset[col] = le.fit_transform(dataset[col])
    label_encoders[col] = le

# Scaling numerical variables
scaler = MinMaxScaler()
scaled_columns = ['Fertility_Index', 'Average_Rainfall(mm)', 'Temperature(°C)']
dataset[scaled_columns] = scaler.fit_transform(dataset[scaled_columns])

# Display the preprocessed dataset
dataset.head()

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import numpy as np

# Splitting the dataset into training and testing sets
X = dataset[['Soil_Type', 'Fertility_Index', 'Average_Rainfall(mm)', 'Temperature(°C)']]
y = dataset['Crop_Suitability']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Simple belief-rule inspired model using weighted sum as a baseline
def belief_rule_model(X, weights):
    # Weighted sum of features, followed by rounding to nearest category
    scores = np.dot(X, weights)
    return np.round(scores).astype(int)

# Define arbitrary weights for the features (can be optimized later)
weights = np.array([0.3, 0.3, 0.2, 0.2])  # Example weights for inputs

# Predicting using the belief rule model
y_pred = belief_rule_model(X_test, weights)

# Clipping predictions to match the number of output categories (0 to max y)
y_pred = np.clip(y_pred, y.min(), y.max())

# Evaluating the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

accuracy, classification_rep

# Adding actual vs. predicted data for better insight
result_df = X_test.copy()
result_df['Actual'] = y_test.values
result_df['Predicted'] = y_pred

# Display a sample of actual vs predicted results
result_df.sample(10)

import pandas as pd
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

def load_and_preprocess_soil_data(file_path):
    df = pd.read_csv(file_path)

    # Encode categorical variables
    label_encoders = {}
    for col in ['Soil_Type', 'Land_Use_Type', 'Crop_Suitability', 'Season']:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

    # Scale numerical variables
    scaler = MinMaxScaler()
    df[['Fertility_Index', 'Average_Rainfall(mm)', 'Temperature(°C)']] = scaler.fit_transform(
        df[['Fertility_Index', 'Average_Rainfall(mm)', 'Temperature(°C)']]
    )
    return df

def belief_rule_model(X, weights):
    scores = (X * weights).sum(axis=1)
    return scores.round().astype(int)

def evaluate_model(y_true, y_pred, y_prob=None):
    accuracy = accuracy_score(y_true, y_pred)
    rmse = mean_squared_error(y_true, y_pred)
    return accuracy * 100, rmse

def main_soil_quality_analysis(file_path):
    df = load_and_preprocess_soil_data(file_path)
    X = df[['Soil_Type', 'Fertility_Index', 'Average_Rainfall(mm)', 'Temperature(°C)']]
    y = df['Crop_Suitability']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    results = []

    # BRBES Model
    weights = [0.3, 0.3, 0.2, 0.2]
    y_pred_brb = belief_rule_model(X_test, weights)
    brbes_acc, brbes_rmse = evaluate_model(y_test, y_pred_brb)
    results.append(['BRBES', brbes_acc, brbes_rmse])

    # Logistic Regression
    lr = LogisticRegression(random_state=42)
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    lr_acc, lr_rmse = evaluate_model(y_test, y_pred_lr)
    results.append(['Logistic Regression', lr_acc, lr_rmse])

    # Random Forest
    rf = RandomForestClassifier(random_state=42)
    rf.fit(X_train, y_train)
    y_pred_rf = rf.predict(X_test)
    rf_acc, rf_rmse = evaluate_model(y_test, y_pred_rf)
    results.append(['Random Forest', rf_acc, rf_rmse])

    # Decision Tree
    dt = DecisionTreeClassifier(random_state=42)
    dt.fit(X_train, y_train)
    y_pred_dt = dt.predict(X_test)
    dt_acc, dt_rmse = evaluate_model(y_test, y_pred_dt)
    results.append(['Decision Tree', dt_acc, dt_rmse])

    result_df = pd.DataFrame(results, columns=['Model', 'Accuracy %', 'RMSE'])
    return result_df

# File path to the dataset
file_path = '/content/bangladesh_divisions_dataset.csv'

# Run the analysis and get results
results_df = main_soil_quality_analysis(file_path)
results_df